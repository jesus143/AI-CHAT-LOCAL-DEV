**Create you AI chat locally**

**html + css** -> frontend <br>
**Nodejs** -> realtime chat <br>
**Flask** -> backend <br>
**ollama** -> the runtime (the engine that loads and runs models). <br>
**phi4-mini:3.8b** -> the model you are running inside Ollama. <br>
